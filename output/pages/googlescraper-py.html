<!DOCTYPE html>
<html lang="en">
<head>
  <link href='//fonts.googleapis.com/css?family=Source+Sans+Pro:300,400,700,400italic' rel='stylesheet' type='text/css'>
  <link rel="stylesheet" type="text/css" href="/theme/css/style.min.css">
  <link rel="stylesheet" type="text/css" href="/theme/css/pygments.min.css">
  <link rel="stylesheet" type="text/css" href="/theme/css/font-awesome.min.css">

  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <meta name="robots" content="index, follow" />
  <meta name="author" content="Nikolai Tschacher" />
  <meta name="description" content="Nikolai Tschacher's ideas and programming around security and computer science" />
<meta property="og:site_name" content="Coding, Learning and IT Security"/>
<meta property="og:type" content="blog"/>
<meta property="og:title" content="Coding, Learning and IT Security"/>
<meta property="og:description" content="Nikolai Tschacher's ideas and programming around security and computer science"/>
<meta property="og:locale" content="en_US"/>
<meta property="og:url" content=""/>
  <title>Coding, Learning and IT Security &ndash; GoogleScraper.py</title>
</head>
<body>
  <aside>
    <div>
      <a href="">
        <img src="/theme/img/profile.png" alt="Coding, Learning and IT Security" title="Coding, Learning and IT Security">
      </a>
      <h1><a href="">Coding, Learning and IT Security</a></h1>
      <p></p>
      <nav>
        <ul class="list">
          <li><a href="/pages/about.html#about">About</a></li>
          <li><a href="/pages/contact.html#contact">Contact</a></li>
          <li><a href="/pages/googlescraper-py.html#googlescraper-py">GoogleScraper.py</a></li>
          <li><a href="/pages/projects.html#projects">Projects</a></li>
          <li><a href="/pages/impressum.html#impressum">Site Notice</a></li>
          <li><a href="/pages/svgcaptcha.html#svgcaptcha">SVGCaptcha</a></li>
        </ul>
      </nav>
      <ul class="social">
        <li><a class="sc-twitter" href="https://twitter.com/incolumitas_" target="_blank"><i class="fa fa-twitter"></i></a></li>
        <li><a class="sc-github" href="https://github.com/NikolaiT" target="_blank"><i class="fa fa-github"></i></a></li>
        <li><a class="sc-rss" href="//incolumitas/feeds/all.atom.xml" target="_blank"><i class="fa fa-rss"></i></a></li>
        <li><a class="sc-stack-overflow" href="http://stackoverflow.com/users/1052496/nikolai-tschacher" target="_blank"><i class="fa fa-stack-overflow"></i></a></li>
      </ul>
    </div>
  </aside>
  <main>
    <nav>
      <a href="">Home</a>
      <a href="/archives.html">Archives</a>
      <a href="/categories.html">Categories</a>
      <a href="/tags.html">Tags</a>
    </nav>

<article>
  <header>
    <h1 id="googlescraper-py">GoogleScraper.py</h1>
  </header>
  <div>
    <h3>GoogleScraper - A simple module to scrape and extract links from Google.</h3>
<h3 id="whatdoesgooglescraper">What does GoogleScraper?</h3>
<p>GoogleScraper parses Google search engine results easily and in a
performant way. It allows you to extract all found links/link titles/
link descriptions and the total results for you query problematically
and your application can do whatever it want with them (Probably some
SEO related research)</p>
<p>There are unlimited use cases:</p>
<ul>
<li>Quickly harvest masses of <a href="http://www.webvivant.com/google-hacking.html" title="Google Dorks">google
    dorks</a>.</li>
<li>Use it as a SEO tool.</li>
<li>Discover trends.</li>
<li>Compile lists of sites to feed your own database.</li>
<li>Many more use cases...</li>
</ul>
<p>GoogleScraper is implemented with the following techniques/software:</p>
<ul>
<li>Written in Python 3.3</li>
<li>Uses multihreading/asynchronous IO (Uses
    <a href="http://twistedmatrix.com/trac/" title="twisted framework">twisted</a>).</li>
<li>Supports parallel google scraping with multiple IP addresses.</li>
<li>Provides proxy support using
    <a href="https://code.google.com/p/socksipy-branch/" title="Socksipy Branch">socksipy</a>:<ul>
<li>Socks5</li>
<li>Socks4</li>
<li>HttpProxy</li>
</ul>
</li>
<li>Support for additional google search futures.</li>
<li>Includes exhaustive research of similar projects!</li>
</ul>
<h3 id="exampleusage">Example Usage</h3>
<div class="highlight"><pre><span class="kn">import</span> <span class="nn">GoogleScraper</span>
<span class="kn">import</span> <span class="nn">urllib.parse</span>

<span class="k">if</span> <span class="n">__name__</span> <span class="o">==</span> <span class="s">&#39;__main__&#39;</span><span class="p">:</span>

    <span class="n">results</span> <span class="o">=</span> <span class="n">GoogleScraper</span><span class="o">.</span><span class="n">scrape</span><span class="p">(</span><span class="s">&#39;HOly shit&#39;</span><span class="p">,</span> <span class="n">number_pages</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">link_title</span><span class="p">,</span> <span class="n">link_snippet</span><span class="p">,</span> <span class="n">link_url</span> <span class="ow">in</span> <span class="n">results</span><span class="p">[</span><span class="s">&#39;results&#39;</span><span class="p">]:</span>
        <span class="c"># You can access all parts of the search results like that</span>
        <span class="c"># link_url.scheme =&gt; URL scheme specifier (Ex: &#39;http&#39;)</span>
        <span class="c"># link_url.netloc =&gt; Network location part (Ex: &#39;www.python.org&#39;)</span>
        <span class="c"># link_url.path =&gt; URL scheme specifier (Ex: &#39;&#39;help/Python.html&#39;&#39;)</span>
        <span class="c"># link_url.params =&gt; Parameters for last path element</span>
        <span class="c"># link_url.query =&gt; Query component</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="k">print</span><span class="p">(</span><span class="n">urllib</span><span class="o">.</span><span class="n">parse</span><span class="o">.</span><span class="n">unquote</span><span class="p">(</span><span class="n">link_url</span><span class="o">.</span><span class="n">geturl</span><span class="p">()))</span> <span class="c"># This reassembles the parts of the url to the whole thing</span>
        <span class="k">except</span><span class="p">:</span>
            <span class="k">pass</span>

<span class="c"># How many urls did we get?</span>
<span class="k">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">results</span><span class="p">[</span><span class="s">&#39;results&#39;</span><span class="p">]))</span>

<span class="c"># How many hits has google found with our keyword?</span>
<span class="k">print</span><span class="p">(</span><span class="n">results</span><span class="p">[</span><span class="s">&#39;num_results_for_kw&#39;</span><span class="p">])</span>
</pre></div>


<h3 id="exampleoutput">Example Output</h3>
<p>This is a <a href="/uploads/2013/12/links.txt" title="example output of search query">example
output</a>
of the above <em>use.py</em>:</p>
<h3 id="directcommandlineusage">Direct command line usage</h3>
<p>In case you want to use GoogleScraper.py as a CLI tool, use it somehow
like this:</p>
<div class="highlight"><pre>python GoogleScraper.py -p 1 -n 25 -q &#39;inurl:&quot;.php?id=555&quot;&#39;
</pre></div>


<p>But be aware that google might recognize you pretty fast as a abuser if
you use such google dorks.</p>
<p>Maybe try a socks proxy then (But don't bet on TOR) [This is just a
example, this socks will probably not work anymore when <em>you are here</em>]</p>
<div class="highlight"><pre>python GoogleScraper.py -p 1 -n 25 -q &#39;i hate google&#39; --proxy=&quot;221.132.35.5:2214&quot;
</pre></div>


<h3>Contact</h3>
<p>If you feel like contacting me, do so and send me a mail. You can find
my contact information on my
<a href="http://incolumitas.com/about/contact/" title="Contact with author">blog</a>.</p>
<h3 id="todolistasof25122013">To-do list (As of 25.12.2013)</h3>
<ul>
<li>Figure out whether to use threads or asynchronous I/O for multiple
    connections.</li>
<li>Determine if is is possible to use one google search session with
    multiple connections that are independent of each other (They have
    different IP's)</li>
</ul>
<h3 id="stableversion">Stable version</h3>
<p>This is a development repository. But you can always find a <a href="http://incolumitas.com/2013/01/06/googlesearch-a-rapid-python-class-to-get-search-results/">working GoogleScraper.py script here</a>.</p>
  </div>
</article>

    <footer>
      <p>&copy; Nikolai Tschacher 2015</p>
<p>Built using <a href="http://getpelican.com" target="_blank">Pelican</a> - <a href="https://github.com/alexandrevicenzi/flex" target="_blank">Flex</a> theme by <a href="http://alexandrevicenzi.com" target="_blank">Alexandre Vicenzi</a></p>    </footer>
  </main>
</body>
</html>