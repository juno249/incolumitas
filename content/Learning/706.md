Title: Another day, another way to scrape!
Date: 2014-03-12 00:58
Author: Nikolai Tschacher
Category: Learning
Tags: Programming, Learning
Slug: 706
Status: draft

Hey!

It's been roughly a month since I dared to type some words. This time
I'll look into scraping. Surely nothing new, but I actually found
another method (Or let's say, I decided to use it, I barely found it
myself).

You probably all know (a tad of sarcasm for the unprepared) that I've
written a little scraping module called
[GoogleScraper.py](https://github.com/NikolaiT/GoogleScraper "GoogleScraper.py")
that scrapes the Google SERP by forging raw HTTP requests. Getting 20
stars on Github showed that there is at least some interest in this are.

But this approach has several hard to overcome drawbacks, such that
there are several ways for the Google Servers to detect that a robot is
using their search engine:

<ul>
<li>
The User-Agent is not one of a browser.

</li>
<li>
The search params are not identical to the ones that browser used by a
human sets:

</li>
-   Javascript generates challenges dynamically on the client side. This
    might include heuristics that try to detect human behaviour.
    Example: Only humans move their mouses and hover over the
    interesting search results

<li>
Robots have a strict requests pattern (very fast requests, without a
random time between the sent packets).

</li>
<li>
Dorks are heavily used

</li>
<li>
No pictures/ads/css/javascript are loaded (like a browser does normally)
which in turn won't trigger certain javascript events

</li>
</ul>

